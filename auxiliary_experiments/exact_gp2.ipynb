{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f288a5a8",
   "metadata": {},
   "source": [
    "### GPyTorch evals\n",
    "\n",
    "Evaluates GPyTorch on some of the datasets on\n",
    "which we benchmarked stochastic variational inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f58ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlparkinson1/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import sklearn, matplotlib.pyplot as plt, numpy as np, os, time\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel\n",
    "\n",
    "if \"benchmark_evals\" not in os.getcwd():\n",
    "    os.chdir(os.path.join(\"..\", \"benchmark_evals\"))\n",
    "\n",
    "home = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f0a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae33c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(target_dir):\n",
    "    os.chdir(target_dir)\n",
    "    xfiles = [f for f in os.listdir() if f.endswith(\"xvalues.npy\")]\n",
    "    yfiles = [f for f in os.listdir() if f.endswith(\"yvalues.npy\")]\n",
    "    xfiles.sort()\n",
    "    yfiles.sort()\n",
    "    x, y = [], []\n",
    "    for i, xfile in enumerate(xfiles):\n",
    "        x.append(np.load(xfile).astype(np.float32))\n",
    "        y.append(np.load(yfiles[i]))\n",
    "    \n",
    "    x = np.vstack(x)\n",
    "    y = np.concatenate(y)\n",
    "    return x, y\n",
    "\n",
    "def get_flattened_xy(target_dir):\n",
    "    os.chdir(target_dir)\n",
    "    xfiles = [f for f in os.listdir() if f.endswith(\"xvalues.npy\")]\n",
    "    yfiles = [f for f in os.listdir() if f.endswith(\"yvalues.npy\")]\n",
    "    xfiles.sort()\n",
    "    yfiles.sort()\n",
    "    x, y = [], []\n",
    "    for i, xfile in enumerate(xfiles):\n",
    "        xinit = np.load(xfile).astype(np.float32)\n",
    "        x.append(xinit.reshape((xinit.shape[0], xinit.shape[1] * xinit.shape[2])))\n",
    "        y.append(np.load(yfiles[i]))\n",
    "    \n",
    "    x = np.vstack(x)\n",
    "    y = np.concatenate(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb89ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(init_model, init_likelihood, train_x, train_y):\n",
    "    init_time = time.time()\n",
    "    init_model.train()\n",
    "    init_likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, init_model)\n",
    "    training_iter = 50\n",
    "\n",
    "    for i in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        output = init_model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        if i % 5 == 0:\n",
    "            print(f'Iter {i+1}')\n",
    "        optimizer.step()\n",
    "\n",
    "    init_model.eval()\n",
    "    init_likelihood.eval()\n",
    "    end_time = time.time()\n",
    "    print(f\"Wallclock time: {end_time - init_time}\")\n",
    "    \n",
    "def eval_model(init_model, init_likelihood, test_x, test_y):\n",
    "    init_model.eval()\n",
    "    init_likelihood.eval()\n",
    "    test_x = torch.tensor(test_x).float().cuda()\n",
    "    with torch.no_grad():\n",
    "        f_preds = init_model(test_x)\n",
    "        y_preds = init_likelihood(model(test_x))\n",
    "\n",
    "        f_mean = f_preds.mean\n",
    "        f_var = f_preds.variance\n",
    "    f_mean = f_mean.cpu().numpy()\n",
    "    print(spearmanr(f_mean, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2135bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273541a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlparkinson1/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:130: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1\n",
      "Iter 6\n",
      "Iter 11\n",
      "Iter 16\n",
      "Iter 21\n",
      "Iter 26\n",
      "Iter 31\n",
      "Iter 36\n",
      "Iter 41\n",
      "Iter 46\n",
      "Wallclock time: 0.38500285148620605\n",
      "SpearmanrResult(correlation=0.6358094289204631, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "trainx, trainy = get_xy(os.path.join(home, \"gb1_eval\", \"onehot\", \"two_vs_rest\", \"train\"))\n",
    "testx, testy = get_xy(os.path.join(home, \"gb1_eval\", \"onehot\", \"two_vs_rest\", \"test\"))\n",
    "\n",
    "trainx = torch.tensor(trainx).float().cuda()\n",
    "trainy = torch.tensor(trainy).float().cuda()\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(trainx, trainy, likelihood)\n",
    "model.cuda()\n",
    "\n",
    "model_training(model, likelihood, trainx, trainy)\n",
    "\n",
    "\n",
    "del trainx\n",
    "\n",
    "eval_model(model, likelihood, testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45bda26",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.68 GiB (GPU 0; 7.93 GiB total capacity; 5.85 GiB already allocated; 1.25 GiB free; 5.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m ExactGPModel(trainx, trainy, likelihood)\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainx\n\u001b[1;32m     16\u001b[0m eval_model(model, likelihood, testx, testy)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mmodel_training\u001b[0;34m(init_model, init_likelihood, train_x, train_y)\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m output \u001b[38;5;241m=\u001b[39m init_model(train_x)\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/module.py:30\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:62\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m     61\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood(function_dist, \u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 62\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/distributions/multivariate_normal.py:168\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    161\u001b[0m         covar \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39m(diff_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m covar_size \u001b[38;5;28;01mfor\u001b[39;00m diff_size, covar_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(diff\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], padded_batch_shape)),\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Get log determininant and first part of quadratic form\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m covar \u001b[38;5;241m=\u001b[39m \u001b[43mcovar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m inv_quad, logdet \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39minv_quad_logdet(inv_quad_rhs\u001b[38;5;241m=\u001b[39mdiff\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), logdet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m([inv_quad, logdet, diff\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)])\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py:187\u001b[0m, in \u001b[0;36mAddedDiagLazyTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    Overriding this is currently necessary to allow for subclasses of AddedDiagLT to be created. For example,\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    consider the following:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    In particular, covar1 would *always* be a standard AddedDiagLazyTensor, but covar2 might be a subtype.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     added_diag_lazy_tsr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation())\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m added_diag_lazy_tsr\u001b[38;5;241m.\u001b[39m_lazy_tensor \u001b[38;5;241m+\u001b[39m added_diag_lazy_tsr\u001b[38;5;241m.\u001b[39m_diag_tensor\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1568\u001b[0m, in \u001b[0;36mLazyTensor.representation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresentation_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1562\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;124;03m    Returns a :obj:`gpytorch.lazy.LazyTensorRepresentationTree` tree object that recursively encodes the\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;124;03m    representation of this lazy tensor. In particular, if the definition of this lazy tensor depends on other\u001b[39;00m\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;124;03m    lazy tensors, the tree is an object that can be used to reconstruct the full structure of this lazy tensor,\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;124;03m    including all subobjects. This is used internally.\u001b[39;00m\n\u001b[1;32m   1567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLazyTensorRepresentationTree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py:13\u001b[0m, in \u001b[0;36mLazyTensorRepresentationTree.__init__\u001b[0;34m(self, lazy_tsr)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m lazy_tsr\u001b[38;5;241m.\u001b[39m_args:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m callable(arg\u001b[38;5;241m.\u001b[39mrepresentation):  \u001b[38;5;66;03m# Is it a lazy tensor?\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         representation_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mslice\u001b[39m(counter, counter \u001b[38;5;241m+\u001b[39m representation_size, \u001b[38;5;28;01mNone\u001b[39;00m), arg\u001b[38;5;241m.\u001b[39mrepresentation_tree()))\n\u001b[1;32m     15\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m representation_size\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:377\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrepresentation()\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Otherwise, we'll evaluate the kernel (or at least its LazyTensor representation) and use its\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# representation\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepresentation()\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:332\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/kernels/kernel.py:402\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    400\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m     res \u001b[38;5;241m=\u001b[39m lazify(\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/module.py:30\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 30\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/gpytorch/kernels/scale_kernel.py:112\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     outputscales \u001b[38;5;241m=\u001b[39m outputscales\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39moutputscales\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43morig_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputscales\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.68 GiB (GPU 0; 7.93 GiB total capacity; 5.85 GiB already allocated; 1.25 GiB free; 5.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainx, trainy = get_flattened_xy(os.path.join(home, \"fluorescence_eval\", \"onehot_conv\", \"standard\", \"train\"))\n",
    "testx, testy = get_flattened_xy(os.path.join(home, \"fluorescence_eval\", \"onehot_conv\", \"standard\", \"test\"))\n",
    "\n",
    "trainx = torch.tensor(trainx).float().cuda()\n",
    "trainy = torch.tensor(trainy).float().cuda()\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(trainx, trainy, likelihood)\n",
    "model.cuda()\n",
    "\n",
    "model_training(model, likelihood, trainx, trainy)\n",
    "\n",
    "\n",
    "del trainx\n",
    "\n",
    "eval_model(model, likelihood, testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de734222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Out of memory on an 8GB RAM GPU (that's what we used to run the SVI vs xGPR benchmark tests)\n",
    "#and...we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a392b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2b99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf638a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4578cc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082c520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7decbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlparkinson1/Documents/gp_proteins/venv_testing/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572.743899345398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.836091045184536, pvalue=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_xy(os.path.join(home, \"gb1_eval\", \"onehot\", \"three_vs_rest\", \"train\"))\n",
    "testx, testy = get_xy(os.path.join(home, \"gb1_eval\", \"onehot\", \"three_vs_rest\", \"test\"))\n",
    "kernel = RBF() * ConstantKernel() + WhiteKernel()\n",
    "wclock = time.time()\n",
    "model = GPR(kernel=kernel, random_state=123, n_restarts_optimizer=5).fit(x,y)\n",
    "print(time.time() - wclock)\n",
    "preds = model.predict(testx)\n",
    "spearmanr(preds, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583ce84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
