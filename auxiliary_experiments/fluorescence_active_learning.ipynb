{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc1946e",
   "metadata": {},
   "source": [
    "### xGPR for active learning on the fluorescence dataset\n",
    "\n",
    "We here compare xGPR with Hie et al. 2020 and show that an approximate GP achieves the same results\n",
    "as an exact GP on this dataset. The code for data preprocessing has been borrowed from\n",
    "https://github.com/brianhie/uncertainty/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f2fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xGPR\n",
    "from xGPR.xGP_Regression import xGPRegression\n",
    "from xGPR.data_handling.dataset_builder import build_online_dataset\n",
    "\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5dfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"auxiliary_experiments\" in os.getcwd():\n",
    "    os.chdir(os.path.join(\"..\", \"benchmark_evals\", \"sarkisyan_et_al\", \"data\",\n",
    "                         \"sarkisyan2016gfp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65dd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is all borrowed from Hie et al., to ensure we preprocess the data in the same way.\n",
    "\n",
    "def acquisition_rank(y_pred, var_pred, beta=1.):\n",
    "    return ss.rankdata(y_pred) + (beta * ss.rankdata(-var_pred))\n",
    "\n",
    "def load_embeddings(fname):\n",
    "    X, meta = [], []\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                mutations, n_mut, brightness = line[1:].split('_')\n",
    "                n_mut = int(n_mut)\n",
    "                brightness = float(brightness)\n",
    "                X.append([ float(x) for x in f.readline().split() ])\n",
    "                meta.append([ mutations, n_mut, brightness ])\n",
    "    X = np.array(X)\n",
    "    meta = pd.DataFrame(meta, columns=[\n",
    "        'mutations', 'n_mut', 'brightness',\n",
    "    ])\n",
    "    return X, meta\n",
    "\n",
    "def split_X(X, meta):\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    mutations_test = []\n",
    "    for i in range(X.shape[0]):\n",
    "        n_mut = meta.n_mut[i]\n",
    "        if n_mut > 1:\n",
    "            X_test.append(X[i])\n",
    "            y_test.append(meta.brightness[i])\n",
    "            mutations_test.append(meta.mutations[i])\n",
    "        else:\n",
    "            X_train.append(X[i])\n",
    "            y_train.append(meta.brightness[i])\n",
    "    return (np.array(X_train), np.array(y_train),\n",
    "            np.array(X_test), np.array(y_test),\n",
    "            mutations_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc71e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "    X, meta = load_embeddings(\n",
    "        'embeddings_.txt'\n",
    "    )\n",
    "    X_train, y_train, X_test, y_test, mutations_test = split_X(\n",
    "        X, meta\n",
    "    )\n",
    "    #Interestingly, Hie et al. rearrange the range of the y-values,\n",
    "    #which actually improves performance. This does not seem to\n",
    "    #have been done by most authors in experiments on the fluorescence\n",
    "    #dataset (e.g. the TAPE benchmark). Note that because of this\n",
    "    #rearrangement, we need to add 3 back to predicted y-values at the end\n",
    "    #of the process.\n",
    "    y_train -= 3.\n",
    "    y_test -= 3.\n",
    "    y_train[y_train < 0.] = 0.\n",
    "    y_test[y_test < 0.] = 0.\n",
    "    \n",
    "    tdset = build_online_dataset(X_train, y_train, chunk_size=2000, normalize_y = False)\n",
    "    return tdset, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1caead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdset, X_train, X_test, y_train, y_test = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff769ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 complete.\n",
      "starting fitting\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Iteration 10\n",
      "Iteration 15\n",
      "Iteration 20\n",
      "Iteration 25\n",
      "Iteration 30\n",
      "Iteration 35\n",
      "Iteration 40\n",
      "Iteration 45\n",
      "Iteration 50\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n"
     ]
    }
   ],
   "source": [
    "#It is also possible to use 1024 variance rffs instead of 2048,\n",
    "#or to use 4096 fitting rffs instead of 8192; performance drops\n",
    "#but only very slightly. training_rffs here is irrelevant\n",
    "#since we use preset hyperparameters instead of tuning.\n",
    "mod = xGPRegression(training_rffs = 12, fitting_rffs = 8192, device = \"gpu\",\n",
    "                    variance_rffs = 2048,\n",
    "                   kernel_choice = \"RBF\", verbose = True)\n",
    "\n",
    "#Like Hie et al. 2020, we use default hyperparameters. We use the same\n",
    "#lengthscale. Hie et al. used lambda**2=0; xGPR won't allow you to do\n",
    "#that for numerical stability reasons, but (1e-6)**2 is pretty\n",
    "#close!\n",
    "preset_hparams = np.log(np.array([1e-6, 1, 1]))\n",
    "preconditioner, ratio = mod.build_preconditioner(tdset,\n",
    "                                         max_rank = 512, method = 'srht',\n",
    "                                                preset_hyperparams = preset_hparams)\n",
    "mod.fit(tdset, preconditioner = preconditioner, \n",
    "        mode = \"cg\", tol=1e-7, preset_hyperparams = preset_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2615833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquisition_rank indicates which test datapoints would be experimentally\n",
    "#evaluated first using a typical Bayesian optimization paradigm\n",
    "preds, var = mod.predict(X_test, chunk_size=2000)\n",
    "rankings = acquisition_rank(preds, var)\n",
    "\n",
    "acq_argsort = np.argsort(-rankings)\n",
    "top_fifty = acq_argsort[:50]\n",
    "top_500 = acq_argsort[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a0eb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.801106301644017, pvalue=0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Surprisingly, our approximate GP outperforms the exact GP in Hie et al. on this\n",
    "#metric. They observed a correlation of 0.78 between acquisition rank and\n",
    "#actual fitness, xGPR is here slightly better.\n",
    "ss.spearmanr(rankings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6d83b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.749814175677\n",
      "3.7211014590436\n"
     ]
    }
   ],
   "source": [
    "#This result is ~ identical to the one in Hie et al.\n",
    "print(np.mean(y_test[top_fifty]) + 3)\n",
    "print(np.mean(y_test[top_500]) + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137100cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
