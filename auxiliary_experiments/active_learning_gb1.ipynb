{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7033de",
   "metadata": {},
   "source": [
    "### Active learning on GB1\n",
    "\n",
    "In this experiment, we test to see how xGPR would perform if used for an active\n",
    "learning protein engineering experiment on the GB1 dataset. GB1 is convenient\n",
    "for this purpose since it includes results for (most) of the 160,000 possible mutants for\n",
    "a protein mutated at four sites, so that we can run an in silico experiment that\n",
    "recapitulates what would happen if we used the same approach in the lab.\n",
    "\n",
    "We here imagine a scenario where an experimenter randomly selects 96 sequences,\n",
    "trains a model on these, then uses an acquisition function (as typical in Bayesian\n",
    "optimization) to pick another 96, experimentally evaluates these etc. The goal\n",
    "is to minimize the number of iterations to achieve a \"good\" result. Fitness\n",
    "of each sequence here is measured from 0 to 1, where 0 is worst and 1 best\n",
    "possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9532b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import xGPR\n",
    "from xGPR.xGP_Regression import xGPRegression\n",
    "from xGPR.data_handling.dataset_builder import build_online_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab5dfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"auxiliary_experiments\" in os.getcwd():\n",
    "    os.chdir(os.path.join(\"..\", \"benchmark_evals\", \"active_learn\", \"encoded_data\"))\n",
    "    gb1_x, gb1_y = np.load(os.path.join(\"GB1\", \"0_block_xvalues.npy\")).astype(np.float64), \\\n",
    "            np.load(os.path.join(\"GB1\", \"0_block_yvalues.npy\")).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53068c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sample(all_x, all_y, random_seed):\n",
    "    rng = np.random.default_rng(123)\n",
    "    ind = rng.permutation(all_x.shape[0])\n",
    "    ind_train, ind_test = ind[:384], ind[384:]\n",
    "    testx, testy = all_x[ind_test,:], all_y[ind_test]\n",
    "    train_dset = build_online_dataset(all_x[ind_train,:],\n",
    "                                      all_y[ind_train], chunk_size=2000)\n",
    "    return train_dset, testx, testy\n",
    "\n",
    "def acquisition_rank(y_pred, var_pred):\n",
    "    return scipy.stats.rankdata(y_pred) + scipy.stats.rankdata(-var_pred)\n",
    "\n",
    "def sample_and_stack(init_trainx, init_trainy, test_x, test_y, model):\n",
    "    preds, var = model.predict(test_x, get_var = True, chunk_size=2000)\n",
    "    rankings = acquisition_rank(preds, var)\n",
    "    acq_argsort = np.argsort(-rankings)\n",
    "    best_idx = acq_argsort[:96]\n",
    "    upper_bound = preds + 1.96 * var\n",
    "    best_idx = np.argsort(upper_bound)[-96:]\n",
    "    sampled_y = test_y[best_idx]\n",
    "\n",
    "    train_x = np.vstack([init_trainx, test_x[best_idx,:]])\n",
    "    train_y = np.concatenate([init_trainy, test_y[best_idx]])\n",
    "    mask = np.ones(test_x.shape[0], dtype=bool)\n",
    "    mask[best_idx] = False\n",
    "    new_test_x = test_x[mask,:]\n",
    "    new_test_y = test_y[mask]\n",
    "    new_train_dset = build_online_dataset(train_x, train_y, chunk_size=2000)\n",
    "    return new_train_dset, new_test_x, new_test_y, sampled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ff769ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting_tuning\n",
      "Now beginning L-BFGS minimization.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 0 completed. Best score is 533.6090861702294.\n",
      "Tuning complete.\n",
      "Chunk 0 complete.\n",
      "Ratio: 0.08050471840240853\n",
      "starting fitting\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n"
     ]
    }
   ],
   "source": [
    "tdset, tx, ty = init_sample(gb1_x, gb1_y, 123)\n",
    "\n",
    "mod = xGPRegression(training_rffs = 512, fitting_rffs = 8192, device = \"gpu\",\n",
    "                    variance_rffs = 1024,\n",
    "                   kernel_choice = \"RBF\", kernel_specific_params =\n",
    "                    {\"split_points\":[21,42,63]}, verbose = True)\n",
    "\n",
    "_ = mod.tune_hyperparams_crude_lbfgs(tdset, max_iter=50, n_restarts=1)\n",
    "#_ = mod.tune_hyperparams_crude_bayes(tdset, max_bayes_iter=30)\n",
    "preconditioner, ratio = mod.build_preconditioner(tdset,\n",
    "                                         max_rank = 256, method = 'srht')\n",
    "print(\"Ratio: %s\"%ratio)\n",
    "mod.fit(tdset, preconditioner = preconditioner, \n",
    "        mode = \"cg\", tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08774569",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdset, tx, ty, sampled_y = sample_and_stack(tdset.xdata_, tdset.ydata_, tx, ty, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "80b20dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting_tuning\n",
      "Now beginning L-BFGS minimization.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 0 completed. Best score is 475.49245402881894.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 1 completed. Best score is 475.49245402881894.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 2 completed. Best score is 475.49245402881894.\n",
      "Tuning complete.\n",
      "Chunk 0 complete.\n",
      "Ratio: 0.3443811331049427\n",
      "starting fitting\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n"
     ]
    }
   ],
   "source": [
    "_ = mod.tune_hyperparams_crude_lbfgs(tdset, max_iter=50, n_restarts=3)\n",
    "#_ = mod.tune_hyperparams_crude_bayes(tdset, max_bayes_iter=30)\n",
    "preconditioner, ratio = mod.build_preconditioner(tdset,\n",
    "                                         max_rank = 256, method = 'srht')\n",
    "print(\"Ratio: %s\"%ratio)\n",
    "mod.fit(tdset, preconditioner = preconditioner, \n",
    "        mode = \"cg\", tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65bb3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "23f1d8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting_tuning\n",
      "Now beginning L-BFGS minimization.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 0 completed. Best score is 547.8332197100323.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 1 completed. Best score is 547.8332197100323.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 2 completed. Best score is 547.8332197100323.\n",
      "Tuning complete.\n",
      "Chunk 0 complete.\n",
      "Ratio: 0.31258206526163373\n",
      "starting fitting\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n"
     ]
    }
   ],
   "source": [
    "tdset, tx, ty, sampled_y = sample_and_stack(tdset.xdata_, tdset.ydata_, tx, ty, mod)\n",
    "_ = mod.tune_hyperparams_crude_lbfgs(tdset, max_iter=50, n_restarts=3)\n",
    "#_ = mod.tune_hyperparams_crude_bayes(tdset, max_bayes_iter=30)\n",
    "preconditioner, ratio = mod.build_preconditioner(tdset,\n",
    "                                         max_rank = 256, method = 'srht')\n",
    "print(\"Ratio: %s\"%ratio)\n",
    "mod.fit(tdset, preconditioner = preconditioner, \n",
    "        mode = \"cg\", tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2fc6258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdset, tx, ty, sampled_y = sample_and_stack(tdset.xdata_, tdset.ydata_, tx, ty, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a9c82f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8622110018596997"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sampled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2615833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting_tuning\n",
      "Now beginning L-BFGS minimization.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 0 completed. Best score is 689.0670149940382.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 1 completed. Best score is 689.0670149940382.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 2 completed. Best score is 689.0670149940382.\n",
      "Tuning complete.\n",
      "Chunk 0 complete.\n",
      "Ratio: 0.4195628245313131\n",
      "starting fitting\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Iteration 10\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n"
     ]
    }
   ],
   "source": [
    "tdset, tx, ty, sampled_y = sample_and_stack(tdset.xdata_, tdset.ydata_, tx, ty, mod)\n",
    "_ = mod.tune_hyperparams_crude_lbfgs(tdset, max_iter=50, n_restarts=3)\n",
    "#_ = mod.tune_hyperparams_crude_bayes(tdset, max_bayes_iter=30)\n",
    "preconditioner, ratio = mod.build_preconditioner(tdset,\n",
    "                                         max_rank = 256, method = 'srht')\n",
    "print(\"Ratio: %s\"%ratio)\n",
    "mod.fit(tdset, preconditioner = preconditioner, \n",
    "        mode = \"cg\", tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b398fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdset, tx, ty, sampled_y = sample_and_stack(tdset.xdata_, tdset.ydata_, tx, ty, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e950f7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8311300290585193"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sampled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5fcc7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting_tuning\n",
      "Now beginning L-BFGS minimization.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 0 completed. Best score is 870.0028169045173.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 1 completed. Best score is 870.0028169045173.\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Evaluating gradient...\n",
      "Restart 2 completed. Best score is 870.0028169045173.\n",
      "Tuning complete.\n",
      "Chunk 0 complete.\n",
      "Ratio: 0.4016716083151071\n",
      "starting fitting\n",
      "Iteration 0\n",
      "Iteration 5\n",
      "Iteration 10\n",
      "Now performing variance calculations...\n",
      "Fitting complete.\n"
     ]
    }
   ],
   "source": [
    "tdset, tx, ty, sampled_y = sample_and_stack(tdset.xdata_, tdset.ydata_, tx, ty, mod)\n",
    "_ = mod.tune_hyperparams_crude_lbfgs(tdset, max_iter=50, n_restarts=3)\n",
    "#_ = mod.tune_hyperparams_crude_bayes(tdset, max_bayes_iter=30)\n",
    "preconditioner, ratio = mod.build_preconditioner(tdset,\n",
    "                                         max_rank = 256, method = 'srht')\n",
    "print(\"Ratio: %s\"%ratio)\n",
    "mod.fit(tdset, preconditioner = preconditioner, \n",
    "        mode = \"cg\", tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "425272ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdset, tx, ty, sampled_y = sample_and_stack(tdset.xdata_, tdset.ydata_, tx, ty, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b759bcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4212812537250494"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sampled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30247a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
